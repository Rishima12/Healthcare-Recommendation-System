{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFDZaWlsphxH",
        "outputId": "332bed94-fa36-4139-b925-23337b1a3555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading and Preprocessing data**"
      ],
      "metadata": {
        "id": "kHU2Llmgs8VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "# Loading and preprocessing each dataset\n",
        "\n",
        "\n",
        "def load_and_preprocess_data(file_path, dataset_name):\n",
        "    # Loading the data\n",
        "    data = pd.read_csv(file_path,encoding='latin1')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Loading and preprocessing each dataset\n",
        "\n",
        "\n",
        "demographic_data = load_and_preprocess_data(\n",
        "    '/content/drive/MyDrive/demographic - demographic.csv',\n",
        "    dataset_name='demographic'\n",
        ")\n",
        "\n",
        "\n",
        "diet_data = load_and_preprocess_data(\n",
        "    '/content/drive/MyDrive/diet - diet.csv',\n",
        "    dataset_name='diet'\n",
        ")\n",
        "\n",
        "\n",
        "examination_data = load_and_preprocess_data(\n",
        "    '/content/drive/MyDrive/examination - examination.csv',\n",
        "    dataset_name='examination'\n",
        ")\n",
        "\n",
        "\n",
        "labs_data = load_and_preprocess_data(\n",
        "    '/content/drive/MyDrive/labs - labs.csv',\n",
        "    dataset_name='labs'\n",
        ")\n",
        "\n",
        "\n",
        "medications_data = load_and_preprocess_data(\n",
        "    '/content/drive/MyDrive/medications - medications.csv',\n",
        "    dataset_name='medications'\n",
        ")\n",
        "labeled_data=load_and_preprocess_data(\n",
        "    '/content/drive/MyDrive/Labeled_data - Sheet1 (1) - Labeled_data - Sheet1 (1).csv',\n",
        "    dataset_name='labeled_data'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "demographic_data = demographic_data.iloc[:, :4]\n",
        "diet_data = diet_data.iloc[:, :5]\n",
        "examination_data = examination_data.iloc[:, :6]\n",
        "labs_data = labs_data.iloc[:, :5]\n",
        "medications_data = medications_data.iloc[:, :3]\n",
        "\n",
        "# Merging the datasets based on common column\n",
        "data = pd.merge(demographic_data, diet_data,how='left')\n",
        "data = pd.merge(data, examination_data,how='left')\n",
        "data = pd.merge(data, labs_data,how='left')\n",
        "data = pd.merge(data, medications_data,how='left')\n",
        "data = pd.merge(data, labeled_data,how='left')\n",
        "data=data.dropna()\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "435u240gvMst",
        "outputId": "dda1823b-4106-45c9-ab37-70116816ba19"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        SEQN  AGE  GENDER  COUNTRY  SUGARS    FATS  FIBERS  WATER_INTAKE  \\\n",
            "1      73557   69       1      1.0  176.47   52.81    10.8         960.0   \n",
            "2      73558   54       1      1.0   44.99  124.29    16.7         360.0   \n",
            "3      73558   54       1      1.0   44.99  124.29    16.7         360.0   \n",
            "4      73558   54       1      1.0   44.99  124.29    16.7         360.0   \n",
            "5      73558   54       1      1.0   44.99  124.29    16.7         360.0   \n",
            "...      ...  ...     ...      ...     ...     ...     ...           ...   \n",
            "20182  83724   80       1      1.0  164.56   69.26    22.2         690.0   \n",
            "20183  83724   80       1      1.0  164.56   69.26    22.2         690.0   \n",
            "20184  83724   80       1      1.0  164.56   69.26    22.2         690.0   \n",
            "20185  83724   80       1      1.0  164.56   69.26    22.2         690.0   \n",
            "20186  83724   80       1      1.0  164.56   69.26    22.2         690.0   \n",
            "\n",
            "       BP_DIA  BP_SYS  HEIGHT  WEIGHT   BMI  CHOLESTROL  HAEMOGLOBIN  \\\n",
            "1        72.0   122.0   171.3    78.3  26.7       167.0         29.9   \n",
            "2        62.0   156.0   176.8    89.5  28.6       170.0         31.0   \n",
            "3        62.0   156.0   176.8    89.5  28.6       170.0         31.0   \n",
            "4        62.0   156.0   176.8    89.5  28.6       170.0         31.0   \n",
            "5        62.0   156.0   176.8    89.5  28.6       170.0         31.0   \n",
            "...       ...     ...     ...     ...   ...         ...          ...   \n",
            "20182    70.0   164.0   176.0    77.1  24.9       157.0         31.8   \n",
            "20183    70.0   164.0   176.0    77.1  24.9       157.0         31.8   \n",
            "20184    70.0   164.0   176.0    77.1  24.9       157.0         31.8   \n",
            "20185    70.0   164.0   176.0    77.1  24.9       157.0         31.8   \n",
            "20186    70.0   164.0   176.0    77.1  24.9       157.0         31.8   \n",
            "\n",
            "       PLATELETS  URINE     DAYS  COUNT    SCORE  \n",
            "1          204.0  0.821   1460.0    2.0  2701.79  \n",
            "2          314.0  1.636    243.0    4.0  6779.99  \n",
            "3          314.0  1.636    365.0    4.0  6779.99  \n",
            "4          314.0  1.636     14.0    4.0  6779.99  \n",
            "5          314.0  1.636     61.0    4.0  6779.99  \n",
            "...          ...    ...      ...    ...      ...  \n",
            "20182      180.0  0.706  10950.0    5.0     1.00  \n",
            "20183      180.0  0.706    182.0    5.0     1.00  \n",
            "20184      180.0  0.706   5475.0    5.0     1.00  \n",
            "20185      180.0  0.706   3650.0    5.0     1.00  \n",
            "20186      180.0  0.706    365.0    5.0     1.00  \n",
            "\n",
            "[8003 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction using CNN**"
      ],
      "metadata": {
        "id": "xy28dB6XL8Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "# Defining input features\n",
        "input_features = ['AGE', 'GENDER','COUNTRY','SUGARS','FATS','FIBERS','WATER_INTAKE',\n",
        "                  'BP_DIA','BP_SYS','HEIGHT','WEIGHT','BMI','CHOLESTROL','HAEMOGLOBIN',\n",
        "                  'PLATELETS','URINE','DAYS','COUNT']\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preparing input data and labels\n",
        "train_features = train_data[input_features]\n",
        "train_labels = train_data['SCORE']\n",
        "\n",
        "test_features = test_data[input_features]\n",
        "test_labels = test_data['SCORE']\n",
        "\n",
        "# Converting NumPy arrays to tensors\n",
        "train_features = tf.convert_to_tensor(train_features.values, dtype=tf.float32)\n",
        "train_labels = tf.convert_to_tensor(train_labels.values, dtype=tf.float32)\n",
        "\n",
        "test_features = tf.convert_to_tensor(test_features.values, dtype=tf.float32)\n",
        "test_labels = tf.convert_to_tensor(test_labels.values, dtype=tf.float32)\n",
        "\n",
        "# Defining the 1D CNN model\n",
        "input_layer = Input(shape=(len(input_features), 1))  # Input shape for 1D CNN\n",
        "conv1d_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(input_layer)\n",
        "maxpooling1d_layer = MaxPooling1D(pool_size=2)(conv1d_layer)\n",
        "flatten_layer = Flatten()(maxpooling1d_layer)\n",
        "dense_layer_1 = Dense(64, activation='relu')(flatten_layer)\n",
        "output_layer = Dense(1, activation='linear')(dense_layer_1)  # Linear activation for regression task\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Training the model\n",
        "model.fit(train_features, train_labels, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluating the model on test data\n",
        "loss = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test Loss (MSE): {loss}\")\n",
        "\n",
        "# Making predictions on new data\n",
        "new_data = pd.DataFrame({\n",
        "    'AGE': [69],\n",
        "    'GENDER': [1],\n",
        "    'COUNTRY': [1.0],\n",
        "    'SUGARS': [176.47],\n",
        "    'FATS': [52.81],\n",
        "    'FIBERS': [10.8],\n",
        "    'WATER_INTAKE': [960.0],\n",
        "    'BP_DIA': [72.0],\n",
        "    'BP_SYS': [122.0],\n",
        "    'HEIGHT': [171.3],\n",
        "    'WEIGHT':[78.3],\n",
        "    'BMI':[26.7],\n",
        "    'CHOLESTROL':[167.0],\n",
        "    'HAEMOGLOBIN':[29.9],\n",
        "    'PLATELETS':[204.0],\n",
        "    'URINE':[0.821],\n",
        "    'DAYS':[1460.0],\n",
        "    'COUNT':[2.0]\n",
        "})\n",
        "\n",
        "# Converting the new data to a tensor\n",
        "new_data = tf.convert_to_tensor(new_data.values, dtype=tf.float32)\n",
        "\n",
        "# Reshaping the input data to match the 1D CNN input shape\n",
        "new_data = tf.reshape(new_data, shape=(1, len(input_features), 1))\n",
        "\n",
        "predicted_scores = model.predict(new_data)\n",
        "print(f\"Predicted Healthcare Score: {predicted_scores[0][0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfAZisgGvabJ",
        "outputId": "e068930e-d18f-4884-d375-219b6156841a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "201/201 [==============================] - 2s 4ms/step - loss: 2736045.5000\n",
            "Epoch 2/10\n",
            "201/201 [==============================] - 1s 4ms/step - loss: 2218711.5000\n",
            "Epoch 3/10\n",
            "201/201 [==============================] - 0s 2ms/step - loss: 2299726.2500\n",
            "Epoch 4/10\n",
            "201/201 [==============================] - 0s 2ms/step - loss: 2169440.7500\n",
            "Epoch 5/10\n",
            "201/201 [==============================] - 0s 2ms/step - loss: 2155644.0000\n",
            "Epoch 6/10\n",
            "201/201 [==============================] - 0s 2ms/step - loss: 2188549.0000\n",
            "Epoch 7/10\n",
            "201/201 [==============================] - 0s 2ms/step - loss: 2147889.2500\n",
            "Epoch 8/10\n",
            "201/201 [==============================] - 0s 2ms/step - loss: 2149138.5000\n",
            "Epoch 9/10\n",
            "201/201 [==============================] - 0s 2ms/step - loss: 2142955.5000\n",
            "Epoch 10/10\n",
            "201/201 [==============================] - 0s 2ms/step - loss: 2143836.5000\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2360360.0000\n",
            "Test Loss (MSE): 2360360.0\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "Predicted Healthcare Score: 2237.3076171875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction using feedforward network**"
      ],
      "metadata": {
        "id": "UtnnXemSMBsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Defining input features\n",
        "input_features = ['AGE', 'GENDER','COUNTRY','SUGARS','FATS','FIBERS','WATER_INTAKE',\n",
        "                  'BP_DIA','BP_SYS','HEIGHT','WEIGHT','BMI','CHOLESTROL','HAEMOGLOBIN',\n",
        "                  'PLATELETS','URINE','DAYS','COUNT']\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.33, random_state=42)\n",
        "\n",
        "# Preparing input data\n",
        "train_features = train_data[input_features]\n",
        "train_labels = train_data['SCORE']\n",
        "\n",
        "train_features = tf.convert_to_tensor(train_features.values, dtype=tf.float32)\n",
        "train_labels = tf.convert_to_tensor(train_labels.values, dtype=tf.float32)\n",
        "\n",
        "# Defining the neural network model\n",
        "input_layer = Input(shape=(len(input_features),))\n",
        "dense_layer_1 = Dense(64, activation='relu')(input_layer)\n",
        "dense_layer_2 = Dense(32, activation='linear')(dense_layer_1)\n",
        "output_layer = Dense(1, activation='linear')(dense_layer_2)  # Linear activation for regression task\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "# Training the model\n",
        "model.fit(train_features, train_labels, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluating the model on test data\n",
        "test_features = test_data[input_features]\n",
        "test_labels = test_data['SCORE']\n",
        "\n",
        "test_features = tf.convert_to_tensor(test_features.values, dtype=tf.float32)\n",
        "test_labels = tf.convert_to_tensor(test_labels.values, dtype=tf.float32)\n",
        "\n",
        "loss = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "\n",
        "# Making predictions on new data\n",
        "new_data = pd.DataFrame({\n",
        "    'AGE': [69],\n",
        "    'GENDER': [1],\n",
        "    'COUNTRY': [1.0],\n",
        "    'SUGARS': [176.47],\n",
        "    'FATS': [52.81],\n",
        "    'FIBERS': [10.8],\n",
        "    'WATER_INTAKE': [960.0],\n",
        "    'BP_DIA': [72.0],\n",
        "    'BP_SYS': [122.0],\n",
        "    'HEIGHT': [171.3],\n",
        "    'WEIGHT':[78.3],\n",
        "    'BMI':[26.7],\n",
        "    'CHOLESTROL':[167.0],\n",
        "    'HAEMOGLOBIN':[29.9],\n",
        "    'PLATELETS':[204.0],\n",
        "    'URINE':[0.821],\n",
        "    'DAYS':[1460.0],\n",
        "    'COUNT':[2.0]\n",
        "})\n",
        "new_data = tf.convert_to_tensor(new_data.values, dtype=tf.float32)\n",
        "\n",
        "predicted_scores = model.predict(new_data)\n",
        "print(f\"Predicted Healthcare Score: {predicted_scores[0][0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5ZtX9W1FiCC",
        "outputId": "860161a1-d098-4a94-b091-6ff95291780e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "168/168 [==============================] - 1s 3ms/step - loss: 1361.4456\n",
            "Epoch 2/10\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1099.7804\n",
            "Epoch 3/10\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1089.5010\n",
            "Epoch 4/10\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1080.6005\n",
            "Epoch 5/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1099.0491\n",
            "Epoch 6/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1087.3910\n",
            "Epoch 7/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1091.8584\n",
            "Epoch 8/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1086.7251\n",
            "Epoch 9/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1086.4760\n",
            "Epoch 10/10\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1072.9752\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 1122.8374\n",
            "Test Loss: 1122.83740234375\n",
            "1/1 [==============================] - 0s 177ms/step\n",
            "Predicted Healthcare Score: 1827.273681640625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction using xgboost**"
      ],
      "metadata": {
        "id": "NoNFet5wMbxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "# Defining input features\n",
        "input_features = ['AGE', 'GENDER','COUNTRY','SUGARS','FATS','FIBERS','WATER_INTAKE',\n",
        "                  'BP_DIA','BP_SYS','HEIGHT','WEIGHT','BMI','CHOLESTROL','HAEMOGLOBIN',\n",
        "                  'PLATELETS','URINE','DAYS','COUNT']\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "X = data[input_features].values\n",
        "y = data['SCORE'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Defining the XGBoost-based recommendation model\n",
        "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=5, learning_rate=0.1)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the model on test data\n",
        "y_pred = model.predict(X_test)\n",
        "mse = np.mean((y_test - y_pred) ** 2)\n",
        "print(f\"Test Mean Squared Error (MSE): {mse}\")\n",
        "\n",
        "# Making predictions on new data\n",
        "new_data = pd.DataFrame({\n",
        "    'AGE': [69],\n",
        "    'GENDER': [1],\n",
        "    'COUNTRY': [1.0],\n",
        "    'SUGARS': [176.47],\n",
        "    'FATS': [52.81],\n",
        "    'FIBERS': [10.8],\n",
        "    'WATER_INTAKE': [960.0],\n",
        "    'BP_DIA': [72.0],\n",
        "    'BP_SYS': [122.0],\n",
        "    'HEIGHT': [171.3],\n",
        "    'WEIGHT':[78.3],\n",
        "    'BMI':[26.7],\n",
        "    'CHOLESTROL':[167.0],\n",
        "    'HAEMOGLOBIN':[29.9],\n",
        "    'PLATELETS':[204.0],\n",
        "    'URINE':[0.821],\n",
        "    'DAYS':[1460.0],\n",
        "    'COUNT':[2.0]\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "predicted_score = model.predict(new_data)\n",
        "print(f\"Predicted Healthcare Score: {predicted_score[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGks0vrEJ-Vp",
        "outputId": "87899b9f-887a-4559-fcdb-eb7f28ee72e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Mean Squared Error (MSE): 879933.7129817194\n",
            "Predicted Healthcare Score: 2081.90625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction using random forests**"
      ],
      "metadata": {
        "id": "VzlmYSCBMjoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Defining input features\n",
        "input_features = ['AGE', 'GENDER','COUNTRY','SUGARS','FATS','FIBERS','WATER_INTAKE',\n",
        "                  'BP_DIA','BP_SYS','HEIGHT','WEIGHT','BMI','CHOLESTROL','HAEMOGLOBIN',\n",
        "                  'PLATELETS','URINE','DAYS','COUNT']\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "X = data[input_features].values\n",
        "y = data['SCORE'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing the input data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# Defining the Random Forest-based recommendation model\n",
        "model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the model on test data\n",
        "y_pred = model.predict(X_test)\n",
        "mse = np.mean((y_test - y_pred) ** 2)\n",
        "print(f\"Test Mean Squared Error (MSE): {mse}\")\n",
        "\n",
        "# Making predictions on new data\n",
        "new_data = pd.DataFrame({\n",
        "    'AGE': [69],\n",
        "    'GENDER': [1],\n",
        "    'COUNTRY': [1.0],\n",
        "    'SUGARS': [176.47],\n",
        "    'FATS': [52.81],\n",
        "    'FIBERS': [10.8],\n",
        "    'WATER_INTAKE': [960.0],\n",
        "    'BP_DIA': [72.0],\n",
        "    'BP_SYS': [122.0],\n",
        "    'HEIGHT': [171.3],\n",
        "    'WEIGHT':[78.3],\n",
        "    'BMI':[26.7],\n",
        "    'CHOLESTROL':[167.0],\n",
        "    'HAEMOGLOBIN':[29.9],\n",
        "    'PLATELETS':[204.0],\n",
        "    'URINE':[0.821],\n",
        "    'DAYS':[1460.0],\n",
        "    'COUNT':[2.0]\n",
        "})\n",
        "new_data = scaler.transform(new_data)\n",
        "\n",
        "predicted_score = model.predict(new_data)\n",
        "print(f\"Predicted Healthcare Score: {predicted_score[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paQNbMxALC05",
        "outputId": "2e037b16-1cef-4332-fa8d-2530a72c18da"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Mean Squared Error (MSE): 1849543.428304031\n",
            "Predicted Healthcare Score: 2250.5584871243004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}